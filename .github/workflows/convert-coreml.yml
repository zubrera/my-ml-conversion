# .github/workflows/convert-coreml.yml

name: Convert MiniLM to CoreML

on:
  workflow_dispatch:
    inputs:
      output_name:
        description: 'Name der .mlmodel-Datei'
        required: true
        default: 'MiniLM_L6_v2.mlmodel'

jobs:
  build:
    runs-on: macos-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          # Pinning huggingface_hub to 0.10.1 avoids cached_download error
          pip install \
            torch==1.12.1 \
            coremltools==6.0 \
            transformers==4.26.1 \
            huggingface_hub==0.10.1 \
            numpy==1.23.5 \
            scikit-learn==1.1.2

      - name: Convert PyTorch → CoreML
        run: |
          python3 - <<'EOF'
          import torch
          import coremltools as ct
          from transformers import AutoModel, AutoTokenizer

          # 1) Modell & Tokenizer laden
          model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
          model.eval()
          tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

          # 2) Dummy-Tokenisierung (max_length=128)
          inputs = tokenizer(
              "Hello world", 
              return_tensors="pt", 
              max_length=128, 
              padding="max_length", 
              truncation=True
          )
          input_ids = inputs["input_ids"]

          # 3) TorchScript trace (strict=False für mögliche dict-Ausgaben)
          traced = torch.jit.trace(model, input_ids, strict=False)

          # 4) CoreML-Konvertierung
          mlmodel = ct.convert(
              traced,
              inputs=[ct.TensorType(name="input_ids", shape=input_ids.shape, dtype=int)],
              convert_to="mlprogram",
              minimum_deployment_target=ct.target.iOS15
          )

          # 5) Speichern
          output = "${{ github.event.inputs.output_name }}"
          mlmodel.save(output)
          print(f"✅ Modell gespeichert als {output}")
          EOF

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: coreml-model
          path: ${{ github.event.inputs.output_name }}
